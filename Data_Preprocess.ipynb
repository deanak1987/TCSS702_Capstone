{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGY0X_DwWuFz"
   },
   "source": [
    "# TCGA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-V7ubdYW1Fs"
   },
   "source": [
    "## Initial Setup\n",
    "\n",
    "Connects to Google Drive\n",
    "Installs and imports dependancies\n",
    "Run whether starting or returning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6XKvnkQO1c1"
   },
   "outputs": [],
   "source": [
    "%ls\n",
    "%cd CancerPrediction\n",
    "from multiprocessing import Process\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from sys import platform\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from openslide import open_slide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import random \n",
    "from PIL import Image\n",
    "plt.style.use(\"ggplot\")\n",
    "import openslide\n",
    "import gc\n",
    "# import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gq5pcvTmKJ0b",
    "outputId": "d9def501-a72e-487c-8f35-1481a1a4c6b5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "process_count = len(os.sched_getaffinity(0))\n",
    "print('Processors available: ', process_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7XZ0vMTYRuu"
   },
   "source": [
    "## Download Selected Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete old - Only use if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img_dir in os.listdir('slides'): \n",
    "#   path = os.path.join('slides', img_dir)\n",
    "#   if os.path.isdir(path) and 'ipynb' not in img_dir:\n",
    "#     shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest_filename = 'slides/gdc_manifest_Tissue_Slides_non_annotated.txt'\n",
    "manifest_filename_diag = 'slides/gdc_manifest_Tissue_Slides_diagnostic.txt'\n",
    "df_manifest = pd.read_csv(manifest_filename, sep='\\t')\n",
    "df_manifest_diag = pd.read_csv(manifest_filename_diag, sep='\\t')\n",
    "df_manifest_all = pd.concat([df_manifest, df_manifest_diag]).drop_duplicates().reset_index(drop=True)\n",
    "print(len(df_manifest_all))\n",
    "list_df = np.array_split(df_manifest, 5)\n",
    "df_manifest_slice = list_df[0]\n",
    "df_manifest_slice.to_csv('slides/gdc_manifest_slice.txt', index=False, sep='\\t')\n",
    "print(len(df_manifest_slice))\n",
    "df_manifest_slice.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNVaBDHkWTUW",
    "outputId": "8e85f8df-c2cd-4e61-aa5e-a57c73b157c4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd slides\n",
    "%ls\n",
    "!chmod +x gdc-client\n",
    "!./gdc-client download -m gdc_manifest_slice.txt\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Image DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manifest_filename = 'slides/gdc_manifest_Tissue_Slides.txt'\n",
    "df_manifest = df_manifest_slice\n",
    "clinic_filename = 'CombinedClinicalManifestData.csv'\n",
    "df_clinic = pd.read_csv(clinic_filename)\n",
    "df_datalabels = df_clinic.merge(df_manifest, on='filename', how='inner', suffixes=('', '_y'))\n",
    "\n",
    "df_datalabels.drop(df_datalabels.filter(regex='_y$').columns, axis=1, inplace=True)\n",
    "df_datalabels['Path'] = df_datalabels['id'].apply(lambda x: '/slides/' + x + '/tiles/')\n",
    "df_datalabels['ER_Label'] = df_datalabels['brca_shared-er_status_by_ihc'].apply(lambda x: 1 if x == 'Positive' else (0 if x == 'Negative' else 2))\n",
    "df_datalabels['PR_Label'] = df_datalabels['brca_shared-pr_status_by_ihc'].apply(lambda x: 1 if x == 'Positive' else (0 if x == 'Negative' else 2))\n",
    "df_datalabels['HER_Label'] = df_datalabels['brca_shared-her2_status_by_ihc'].apply(lambda x: 1 if x == 'Positive' else (0 if x == 'Negative' else 2))\n",
    "df_datalabels['NNN_label'] = df_datalabels[['ER_Label', 'PR_Label', 'HER_Label']].apply(lambda x: 1 if (x.ER_Label == 0 and x.PR_Label == 0 and x.HER_Label == 0) else 0, axis=1)\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('md5')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('size')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('state')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('bcr_patient_barcode')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('shared-gender')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-vital_status')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-race_list')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('shared-tissue_source_site')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('shared-patient_id')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('shared-bcr_patient_uuid')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-patient_consent_status')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-icd_o_3_site')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-icd_o_3_histology')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-icd_10')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-initial_pathologic_dx_days_to')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('shared_stage-stage_event')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-form_completion_day')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-form_completion_month')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('clin_shared-form_completion_year')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('images')]\n",
    "print(len(df_datalabels))\n",
    "df_datalabels.to_csv('slides/model_datalabels.csv', index=False)\n",
    "\n",
    "df_datalabels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize files if continuing work after hiatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datalabels = pd.read_csv('slides/model_datalabels.csv')\n",
    "# manifest_filename = 'slides/gdc_manifest_Tissue_Slides.txt'\n",
    "# df_manifest = pd.read_csv(manifest_filename, sep='\\t')\n",
    "# clinic_filename = 'CombinedClinicalManifestData.csv'\n",
    "# df_clinic = pd.read_csv(clinic_filename)\n",
    "# images_to_process = pd.read_csv('slides/images_to_process.csv')\n",
    "# print(len(images_to_process))\n",
    "# images_to_process.head()\n",
    "# # df_test_idea = images_to_process\n",
    "# # df_test_idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i8st7lonVBT"
   },
   "source": [
    "## Process the slides into tiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCTKUUUUxKDm"
   },
   "source": [
    "#### Preprocessing Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbE8Mua5X7aj"
   },
   "outputs": [],
   "source": [
    "def norm_HnE(img, Io=240, alpha=1, beta=0.15):\n",
    "    # Step 1: Convert RGB to OD ###################\n",
    "    # reference H&E OD matrix.\n",
    "    # Can be updated if you know the best values for your image.\n",
    "    # Otherwise use the following default values.\n",
    "    # Read the above referenced papers on this topic.\n",
    "    HERef = np.array([[0.5626, 0.2159],\n",
    "                      [0.7201, 0.8012],\n",
    "                      [0.4062, 0.5581]])\n",
    "    # reference maximum stain concentrations for H&E\n",
    "    maxCRef = np.array([1.9705, 1.0308])\n",
    "\n",
    "    # extract the height, width and num of channels of image\n",
    "    h, w, c = img.shape\n",
    "\n",
    "    # reshape image to multiple rows and 3 columns.\n",
    "    # Num of rows depends on the image size (wxh)\n",
    "    img = img.reshape((-1, 3))\n",
    "\n",
    "    # calculate optical density\n",
    "    # OD = −log10(I)\n",
    "    # OD = -np.log10(img+0.004)  #Use this when reading images with skimage\n",
    "    # Adding 0.004 just to avoid log of zero.\n",
    "\n",
    "    \n",
    "    OD = -np.log10((img.astype(float) + 1) / Io)  # Use this for opencv imread\n",
    "    # Add 1 in case any pixels in the image have a value of 0 (log 0 is indeterminate)\n",
    "\n",
    "    # Step 2: Remove data with OD intensity less than β ############\n",
    "    # remove transparent pixels (clear region with no tissue)\n",
    "    ODhat = OD[~np.any(OD < beta, axis=1)]  # Returns an array where OD values are above beta\n",
    "    # Check by printing ODhat.min()\n",
    "\n",
    "    # Step 3: Calculate SVD on the OD tuples ######################\n",
    "    # Estimate covariance matrix of ODhat (transposed)\n",
    "    # and then compute eigen values & eigenvectors.\n",
    "    eigvals, eigvecs = np.linalg.eigh(np.cov(ODhat.T))\n",
    "\n",
    "    # Step 4: Create plane from the SVD directions with two largest values ######\n",
    "    # project on the plane spanned by the eigenvectors corresponding to the two\n",
    "    # largest eigenvalues\n",
    "    That = ODhat.dot(eigvecs[:, 1:3])  # Dot product\n",
    "\n",
    "    # Step 5: Project data onto the plane, and normalize to unit length ###########\n",
    "    # Step 6: Calculate angle of each point wrt the first SVD direction ########\n",
    "    # find the min and max vectors and project back to OD space\n",
    "    phi = np.arctan2(That[:, 1], That[:, 0])\n",
    "\n",
    "    minPhi = np.percentile(phi, alpha)\n",
    "    maxPhi = np.percentile(phi, 100 - alpha)\n",
    "\n",
    "    vMin = eigvecs[:, 1:3].dot(np.array([(np.cos(minPhi), np.sin(minPhi))]).T)\n",
    "    vMax = eigvecs[:, 1:3].dot(np.array([(np.cos(maxPhi), np.sin(maxPhi))]).T)\n",
    "\n",
    "    # a heuristic to make the vector corresponding to hematoxylin first and the\n",
    "    # one corresponding to eosin second\n",
    "    if vMin[0] > vMax[0]:\n",
    "        HE = np.array((vMin[:, 0], vMax[:, 0])).T\n",
    "\n",
    "    else:\n",
    "        HE = np.array((vMax[:, 0], vMin[:, 0])).T\n",
    "\n",
    "    # rows correspond to channels (RGB), columns to OD values\n",
    "    Y = np.reshape(OD, (-1, 3)).T\n",
    "\n",
    "    # determine concentrations of the individual stains\n",
    "    C = np.linalg.lstsq(HE, Y, rcond=None)[0]\n",
    "\n",
    "    # normalize stain concentrations\n",
    "    maxC = np.array([np.percentile(C[0, :], 99), np.percentile(C[1, :], 99)])\n",
    "    tmp = np.divide(maxC, maxCRef)\n",
    "    C2 = np.divide(C, tmp[:, np.newaxis])\n",
    "\n",
    "    # Step 8: Convert extreme values back to OD space\n",
    "    # recreate the normalized image using reference mixing matrix\n",
    "\n",
    "    Inorm = np.multiply(Io, np.exp(-HERef.dot(C2)))\n",
    "    Inorm[Inorm > 255] = 254\n",
    "    Inorm = np.reshape(Inorm.T, (h, w, 3)).astype(np.uint8)\n",
    "\n",
    "    # Separating H and E components\n",
    "\n",
    "    H = np.multiply(Io, np.exp(np.expand_dims(-HERef[:, 0], axis=1).dot(np.expand_dims(C2[0, :], axis=0))))\n",
    "    H[H > 255] = 254\n",
    "    H = np.reshape(H.T, (h, w, 3)).astype(np.uint8)\n",
    "\n",
    "    E = np.multiply(Io, np.exp(np.expand_dims(-HERef[:, 1], axis=1).dot(np.expand_dims(C2[1, :], axis=0))))\n",
    "    E[E > 255] = 254\n",
    "    E = np.reshape(E.T, (h, w, 3)).astype(np.uint8)\n",
    "\n",
    "    return Inorm, H, E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfmhqm8qX8YN"
   },
   "outputs": [],
   "source": [
    "def is_blurry(image, threshold):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the Laplacian of the image\n",
    "    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    # print(f'Blurriness: {laplacian_var}')\n",
    "    # Check if the variance is below the threshold\n",
    "    return laplacian_var < threshold\n",
    "\n",
    "\n",
    "def save_loop(row1, col1, directory, tiles, imagename, levelnum):\n",
    "    # df = pd.DataFrame(columns=['filename', 'ER_Label'])\n",
    "    for row in row1:\n",
    "        for col in col1:\n",
    "            tile_name = os.path.join(directory, imagename + '_%d_%d' % (col, row))\n",
    "            # print(\"Now saving tile with title: \", tile_name)\n",
    "            temp_tile = tiles.get_tile(levelnum, (col, row))\n",
    "            temp_tile_rgb = temp_tile.convert('RGB')\n",
    "            temp_tile_np = np.array(temp_tile_rgb)\n",
    "            #################################################\n",
    "            # CHANGE MADE - PLEASE VERIFY\n",
    "            if temp_tile_np.mean() < 180 and np.std(np.mean(temp_tile_np, axis=(0, 1))) > 5 and temp_tile_np.shape == (256, 256, 3) and not is_blurry(temp_tile_np, 250):\n",
    "                # print(\"****Good tile number:\", tile_name)\n",
    "                plt.imsave(tile_name + \".png\", temp_tile_np)\n",
    "    # del temp_tile_np, temp_tile_rgb, temp_tile\n",
    "    # gc.collect()\n",
    "    # norm_img, H_img, E_img = norm_HnE(temp_tile_np, Io=240, alpha=1, beta=0.15)\n",
    "    #\n",
    "    # #Save the norm tile, H and E tiles\n",
    "    # plt.imsave(tile_name + \"_norm.png\", norm_img)\n",
    "    # plt.imsave(tile_name + \"_H.png\", H_img)\n",
    "    # plt.imsave(tile_name + \"_E.png\", E_img)\n",
    "\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_NHbRSUYBgI"
   },
   "source": [
    "### Segment the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_process = df_datalabels # If starting new\n",
    "# images_to_process = pd.read_csv('slides/images_to_process.csv')  # If resuming from previous\n",
    "\n",
    "images_to_process.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zgxgofYphGbU",
    "outputId": "638decde-9bc2-49b0-ecd7-69440356c195",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "# import pyvips\n",
    "# manifest = df_datalabels\n",
    "\n",
    "SLIDES_PATH = './slides'\n",
    "num_to_process = len(images_to_process)\n",
    "drop = []\n",
    "for index, row in images_to_process.iterrows():\n",
    "    tile_dir = f\"{SLIDES_PATH}/{row.id}/tiles\"\n",
    "    process_count = math.isqrt(150)\n",
    "    # process_count = math.isqrt(len(os.sched_getaffinity(0)))\n",
    "    print('Processors available: ', process_count ** 2)\n",
    "    print(row.id)\n",
    "\n",
    "\n",
    "    # Load the slide file (svs) into an object.\n",
    "    slide = open_slide(f\"{SLIDES_PATH}/{row.id}/{row.filename}\")\n",
    "\n",
    "    slide_props = slide.properties\n",
    "\n",
    "    try:\n",
    "        objective = float(slide.properties[openslide.PROPERTY_NAME_OBJECTIVE_POWER])\n",
    "         # get slide dimensions for the level 0 - max resolution level\n",
    "        slide_dims = slide.dimensions\n",
    "        # print(slide_dims)\n",
    "\n",
    "        # Get slide dims at each level. Remember that whole slide images store information\n",
    "        # as pyramid at various levels\n",
    "        dims = slide.level_dimensions\n",
    "        print(f'{objective}: {dims}')\n",
    "        \n",
    "        num_levels = len(dims)\n",
    "        # By how much are levels downsampled from the original image?\n",
    "        factors = slide.level_downsamples\n",
    "        # Copy an image from a level\n",
    "        level4_dim = dims[len(dims)-1]\n",
    "        \n",
    "        # Size of your output image\n",
    "        # Remember that the output would be a RGBA image (Not, RGB)\n",
    "        # Generate object for tiles using the DeepZoomGenerator\n",
    "        tiles = DeepZoomGenerator(slide, tile_size=256, overlap=0, limit_bounds=False)\n",
    "        if objective == 20:\n",
    "            if len(dims) == 4:\n",
    "                take = 1\n",
    "            else:\n",
    "                take = 1\n",
    "            level_num = len(tiles.level_tiles) - take\n",
    "            dim_lev = len(dims) - 1\n",
    "        else:\n",
    "            if len(dims) == 4:\n",
    "                take = 2\n",
    "            else:\n",
    "                take = 2\n",
    "            level_num = len(tiles.level_tiles) - take\n",
    "            dim_lev = len(dims) - 1\n",
    "\n",
    "        print(f'level_num: {level_num} out of {len(tiles.level_tiles) - 1}')\n",
    "        level4_img = slide.read_region((0, 0), dim_lev, level4_dim)  # Pillow object, mode=RGBA\n",
    "        \n",
    "        \n",
    "        # Convert the image to RGB\n",
    "        level4_img_RGB = level4_img.convert('RGB')\n",
    "        plt.imshow(level4_img_RGB)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "        # Generating tiles for deep learning training or other processing purposes\n",
    "        # We can use read_region function and slide over the large image to extract tiles\n",
    "        # but an easier approach would be to use DeepZoom based generator.\n",
    "        # https://openslide.org/api/python/\n",
    "        # Here, we have divided our svs into tiles of size 256 with no overlap.\n",
    "        # The tiles object also contains data at many levels.\n",
    "        if len(tiles.level_tiles) > level_num:\n",
    "            if os.path.exists(tile_dir):\n",
    "                shutil.rmtree(tile_dir)\n",
    "            os.makedirs(tile_dir, exist_ok=True)\n",
    "            level_dim = tiles.level_tiles[level_num]\n",
    "            \n",
    "            image_dim = tiles.level_dimensions[level_num]\n",
    "            print(level_dim)\n",
    "            print(f'Level {level_num}\\'s dimensions: {image_dim}')\n",
    "            # Preview a tile with tissue data\n",
    "            while(True):\n",
    "                midx = random.randint(0, level_dim[0])\n",
    "                midy = random.randint(0, level_dim[1])\n",
    "                try: \n",
    "                    tile_dims = tiles.get_tile_dimensions(level_num, (\n",
    "                    midx, midy))  # Provide deep zoom level and address (column, row)\n",
    "                    single_tile = tiles.get_tile(level_num, (\n",
    "                        midx, midy))  # Provide deep zoom level and address (column, row)\n",
    "                    single_tile_array = np.asarray(single_tile)\n",
    "                    if single_tile_array.mean() < 180 and np.std(np.mean(single_tile_array, axis=(0, 1))) > 5 and single_tile_array.shape == (256, 256, 3) and not is_blurry(single_tile_array,100):\n",
    "                        single_tile_RGB = single_tile.convert('RGB')\n",
    "                        break\n",
    "                except ValueError as ve:\n",
    "                    pass\n",
    "            print(\"Tile \", (midx, midy), \"'s shape at level \", level_num, \" is: \", tile_dims)\n",
    "            plt.imshow(single_tile_RGB)\n",
    "            plt.show()\n",
    "\n",
    "          \n",
    "            # Saving each tile to local directory\n",
    "            cols, rows = tiles.level_tiles[level_num - 1]\n",
    "            \n",
    "            t_rows = tuple(split(range(rows), process_count))\n",
    "            t_cols = tuple(split(range(cols), process_count))\n",
    "            processes = []\n",
    "            \n",
    "            tic = time.time()\n",
    "            # Using multiprocessing to speed up the process\n",
    "            for i in range(process_count):\n",
    "                for j in range(process_count):\n",
    "                    p = Process(target=save_loop, args=(t_rows[i], t_cols[j], tile_dir, tiles,row.filename[:-4],\n",
    "                                                        level_num - 1, ))\n",
    "                    p.start()\n",
    "                    processes.append(p)\n",
    "            gc.collect()\n",
    "            for p in processes:\n",
    "                p.join()\n",
    "            print(f'Time to process image is {time.time() - tic} seconds')\n",
    "            files = os.listdir(tile_dir)\n",
    "            print(f'Completed {tile_dir} {index + 1}/{num_to_process}')\n",
    "            tile_count = len(os.listdir(tile_dir))\n",
    "            print(f'Number of tiles: {tile_count}\\n')\n",
    "            images_to_process = images_to_process[images_to_process.id != row.id]\n",
    "            images_to_process.to_csv('slides/images_to_process.csv', index=False)  \n",
    "            ####### os.remove(f\"{SLIDES_PATH}/{row.id}/{row.filename}\")\n",
    "        else:\n",
    "            print('Image does not reach desireable level.\\n')\n",
    "            drop.append(row.id)\n",
    "            shutil.rmtree(f\"{SLIDES_PATH}/{row.id}\")\n",
    "    except KeyError as e:\n",
    "        print(f'KeyError, on objective power. Removing slide')\n",
    "        images_to_process = images_to_process[images_to_process.id != row.id]\n",
    "        drop.append(row.id)\n",
    "        print()\n",
    "for item in drop:\n",
    "    df_datalabels = df_datalabels[df_datalabels['id'] != item]\n",
    "    images_to_process = images_to_process[images_to_process.id != row.id]\n",
    "df_datalabels.to_csv('slides/model_datalabels.csv', index=False)\n",
    "\n",
    "# # Memory cleanup\n",
    "# del processes, process_count, t_rows, t_cols, single_tile, single_tile_RGB\n",
    "# del level_dim, tile_dims, level4_img_np, level4_img, tiles\n",
    "# del slide, dims\n",
    "\n",
    "print(f\"Complete. Removed {len(drop)} files due to insufficient level depth.\")\n",
    "\n",
    "\n",
    "## Dataframe for tiles and locations for tile dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the WSI Tile Filepath Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 600
    },
    "id": "CBg-deUi1nKO",
    "outputId": "b8412ea5-d3ff-4c19-a94a-b319d213ec76"
   },
   "outputs": [],
   "source": [
    "path = 'slides'\n",
    "name = 'tile_data.csv'\n",
    "df_datalabels.reset_index(drop=True)\n",
    "for img_dir in os.listdir(path): \n",
    "  if os.path.isdir(os.path.join(path, img_dir)) and 'ipynb' not in img_dir:\n",
    "    file_path = []\n",
    "    for file in glob.glob(os.path.join(path, img_dir, 'tiles', '*.png')):\n",
    "      file_path.append(file)\n",
    "    df = pd.DataFrame()\n",
    "    df['TilePath'] = file_path\n",
    "    df.to_csv(os.path.join(path, img_dir, name), index=False)\n",
    "\n",
    "df_datalabels['Tile_DF'] = df_datalabels.apply(lambda x: os.path.join(path, x.id, name), axis=1)\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('index')]\n",
    "df_datalabels = df_datalabels.loc[:, ~df_datalabels.columns.str.contains('Unnamed')]\n",
    "df_datalabels.to_csv('slides/model_datalabels_new.csv', index=False)\n",
    "\n",
    "# Memory cleanup\n",
    "del file_path, df\n",
    "\n",
    "df_datalabels.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove .svs file to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qU4gYP16uSkv"
   },
   "outputs": [],
   "source": [
    "SLIDES_PATH = './slides'\n",
    "for index, row in df_datalabels.iterrows():\n",
    "    os.remove(f\"{SLIDES_PATH}/{row.id}/{row.filename}\")\n",
    "    # shutil.rmtree(f\"{SLIDES_PATH}/{row.id}/logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop insufficient tiled images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "wR0vFoO1uSkw",
    "outputId": "135d2055-d702-431e-fb68-7e4446970b27",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drops images with insufficient number of tiles\n",
    "n = 50 # Minimum number of tiles to keep WSIs\n",
    "drop = []\n",
    "for i in range(len(df_datalabels)):\n",
    "  tile_count = len(pd.read_csv(df_datalabels.iloc[i]['Tile_DF']))\n",
    "  if tile_count < n:\n",
    "    drop.append(df_datalabels.iloc[i]['id'])\n",
    "    print(f'{df_datalabels.iloc[i].id} with {tile_count} tiles')\n",
    "  \n",
    "df_reduced = df_datalabels[~df_datalabels.id.isin(drop)]\n",
    "# df_reduced.to_csv('slides/reduce_model_labels.csv')\n",
    "print(f'Number of usable samples: {len(df_reduced)}, number of samples removed: {len(drop)}')\n",
    "del tile_count, drop\n",
    "\n",
    "df_reduced.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "e-V7ubdYW1Fs",
    "gJOswNVSUn8e",
    "W7XZ0vMTYRuu",
    "4i8st7lonVBT",
    "pCTKUUUUxKDm",
    "XsYUp2QF8RK_",
    "5iDoBFgbm71E",
    "6kEnbSD-m3fQ",
    "Rj7juXaeNTWG",
    "SUxncFoYNJQp",
    "oidOd6iegPx0"
   ],
   "gpuClass": "premium",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
